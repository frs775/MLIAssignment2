{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "# plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "sns.set()\n",
    "# Define figure sizes\n",
    "plt.rcParams.update({'figure.figsize': (8, 5), 'figure.dpi': 120})\n",
    "\n",
    "# Data management libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from dateutil.parser import parse \n",
    "\n",
    "# Machine Learning libraries\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_predict\n",
    "import scipy as sp\n",
    "\n",
    "# Others\n",
    "import math\n",
    "from mltools import forecast_tools as FT\n",
    "import scipy.stats as st\n",
    "\n",
    "# Non linear models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neural_network import  MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from mltools import model_tools as MT\n",
    "from mltools import regression_tools as RT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('UnemploymentSpain.dat', sep = '\\t')\n",
    "dates = df['DATE']\n",
    "df.drop(columns=['DATE'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a time series\n",
    "fig, ax = plt.subplots()\n",
    "for col in df.columns.values.tolist():\n",
    "    ax.plot(col, data=df, label=col, alpha=0.8)\n",
    "ax.set(title='Time series data', ylabel='Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load time series values\n",
    "df_ts = df[['TOTAL']]\n",
    "df_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF of the time series -> identify significant lags and order\n",
    "plt.figure(figsize=[15,15])\n",
    "FT.ts_display(df_ts)\n",
    "\n",
    "# No estacionaria en media\n",
    "# Se observa cierta estacionalidad en PACF, no podemos identificar estacionalidad a simple vista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Stabilize the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-cox transformation\n",
    "lmbda = FT.boxcox_lambda_plot(df_ts, window_width=12)\n",
    "\n",
    "# No estacionaria en varianza -> Transformacion Box-cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Box Cox\n",
    "# Indica si queremos transformacion logaritmica\n",
    "BOX_COX = True\n",
    "if BOX_COX:\n",
    "    # SELECIONAR DE GRAFICO ANTERIOR\n",
    "    lmbda = 0.1608\n",
    "    z = st.boxcox(df_ts.values[:,0], lmbda = lmbda) #Convert to positive\n",
    "    #z,lmbda = st.boxcox(df_ts.values[:,0] - min(df_ts.values) + 1) #Convert to positive and automatic selection of lmbda\n",
    "    z = pd.DataFrame(z, columns=df_ts.columns.values.tolist())\n",
    "else:\n",
    "    z = df_ts\n",
    "\n",
    "FT.ts_display(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Box Cox of transformed series\n",
    "FT.boxcox_lambda_plot(z, window_width=12)\n",
    "\n",
    "# Estacionaria en varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze stationarity (mean?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative test - Augmented Dickey Fuller Test\n",
    "# SI P-VALOR MAYOR QUE 0.05 NECESITAS DIFERENCIAR\n",
    "result = adfuller(z.values)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "# No estacionaria en media -> Diferenciacion regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference of the time series\n",
    "# Regular\n",
    "d = 1\n",
    "# Estacional\n",
    "D = 1\n",
    "S = 12 # Seasonality of 12 days\n",
    "\n",
    "Bz = z\n",
    "for diff in range(d):\n",
    "    Bz = Bz.diff().dropna() # drop first NA value\n",
    "for seas_diff in range(D):\n",
    "    Bz = Bz.diff(S).dropna() # drop first NA values\n",
    "plt.figure(figsize=[15,15])\n",
    "FT.ts_display(Bz,lags=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Con dif regular se observa periodicidad de 12 empezando en 0 (y en 9 de forma más sutil)\n",
    "+ ¿Diferenciar primero estacionalmente?\n",
    "+ Tras diferenciar estacionalmente se observa: Elementos no modelados antes de 100 (crisis 2008) y sobre 250 (covid-19), se pueden modelas con variables impulso (sarimax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Fit SARIMA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Regular: AR(1)\n",
    "+ Estacional: MA(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model with estimated order\n",
    "sarima_fit = SARIMAX(z, \n",
    "                    # D: NUM DIFERENCIACIONES HECHAS\n",
    "                    order=(1,1,0), # Regular components (p, d, q)\n",
    "                    seasonal_order=(0, 1, 1, 12), # Seasonal components (p, d, q, s)\n",
    "                    trend= 'n', # Type of trend: ['c','t','n','ct'] --> [constant, linear, no trend, constant and linear]\n",
    "                    enforce_invertibility=False, \n",
    "                    enforce_stationarity=False).fit()\n",
    "\n",
    "print(sarima_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ AIC =  536.253, buscamos que sea lo más bajo posible\n",
    "+ Todos los coeficientes siginificativos\n",
    "+ Modelo SARIMA más simple posible que se adecue al comportamiento de la serie temporal\n",
    "+ Ljung-Box test ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residuals analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residual error\n",
    "plt.figure(figsize=[15,15])\n",
    "FT.check_residuals(pd.DataFrame(sarima_fit.resid.loc[100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Ljung-Box test indica que los residuos son independientes (p-valor > alpha -> No rechazamos H_0:{Residuos independientes})\n",
    "+ Como ya se comentó, existe comportamiento no modelado en la serie temporal\n",
    "+ Residuos aproximadamente normal, aparecen outliers en la cola derecha, comportamiento no modelado o outliers\n",
    "+ De ACF y PACF se observa que el residuo no es ruido blanco, existen correlaciones significativas -> No se ha modelado todo el comportamiento\n",
    "+ Solo a partir de 100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Desde 0, comportamiento extraño al inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain forecasts for in-sample and out-of-sample\n",
    "# Inicio y horizonte\n",
    "start = 200\n",
    "horizon = 20\n",
    "end = df_ts.shape[0] + horizon\n",
    "\n",
    "pred = sarima_fit.get_prediction(start=start, end= end, dynamic=False)\n",
    "yhat = pred.predicted_mean\n",
    "yhat_conf_int = pred.conf_int(alpha=0.05)\n",
    "\n",
    "#Undo Box-cox transform if necessary\n",
    "if BOX_COX:\n",
    "    yhat = sp.special.inv_boxcox(yhat, lmbda)\n",
    "    yhat_conf_int = sp.special.inv_boxcox(yhat_conf_int, lmbda)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.fill_between(yhat_conf_int.index,\n",
    "                yhat_conf_int.iloc[:, 0],\n",
    "                yhat_conf_int.iloc[:, 1], color='k', alpha=.2)\n",
    "plt.plot(df_ts.loc[start:])\n",
    "plt.plot(yhat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction of out_of_sample and confidence intervals\n",
    "# If using dynamic = True, the forecast are used as real data\n",
    "horizon = 20\n",
    "end = df_ts.shape[0] + horizon\n",
    "\n",
    "# COMANDO PREDICCION\n",
    "pred = sarima_fit.get_forecast(steps=horizon, dynamic=False)\n",
    "yhat = pred.predicted_mean\n",
    "yhat_conf_int = pred.conf_int(alpha=0.05)\n",
    "\n",
    "#Undo Box-cox transform if necessary\n",
    "if BOX_COX:\n",
    "    yhat = sp.special.inv_boxcox(yhat, lmbda)\n",
    "    yhat_conf_int = sp.special.inv_boxcox(yhat_conf_int, lmbda)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[15,15])\n",
    "plt.fill_between(yhat_conf_int.index,\n",
    "                yhat_conf_int.iloc[:, 0],\n",
    "                yhat_conf_int.iloc[:, 1], color='k', alpha=.2)\n",
    "plt.plot(df_ts.loc[1000:])\n",
    "plt.plot(yhat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# November 2022 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediccion para steps = 1 (Escala 1 e6)\n",
    "predPreBC = sarima_fit.get_forecast(steps=1, dynamic=False).predicted_mean\n",
    "if BOX_COX:\n",
    "    pred = sp.special.inv_boxcox(predPreBC, lmbda)\n",
    "\n",
    "print('Prediction:', round(pred.values[0]), 'parados en Noviembre de 2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Variables impulso: Crisis 2008, Covid-19\n",
    "+ Visualización + Diferenciaciones realizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit SARIMAX model\n",
    "+ Regular: AR(1)\n",
    "+ Estacional: MA(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear variables impulso\n",
    "# Observando df_ts: Covid-19: 229-241\n",
    "psI = 229\n",
    "exp = np.zeros(len(df_ts))\n",
    "exp[psI] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 opcion: Crecimiento en diferentes etapas, diferentes variables impulso\n",
    "exp1 = np.zeros(len(df_ts))\n",
    "exp2 = np.zeros(len(df_ts))\n",
    "exp1[229] = 1\n",
    "exp2[230] = 1\n",
    "exp = np.matrix([exp1, exp2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model with estimated order\n",
    "sarimax_fit = SARIMAX(endog = z, \n",
    "                    exog = exp,\n",
    "                    # D: NUM DIFERENCIACIONES HECHAS\n",
    "                    order=(1,1,0), # Regular components (p, d, q)\n",
    "                    seasonal_order=(0, 1, 1, 12), # Seasonal components (p, d, q, s)\n",
    "                    trend= 'n', # Type of trend: ['c','t','n','ct'] --> [constant, linear, no trend, constant and linear]\n",
    "                    enforce_invertibility=False, \n",
    "                    enforce_stationarity=False).fit()\n",
    "\n",
    "print(sarimax_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ AIC = 465.908 buscamos que sea lo más bajo posible\n",
    "+ Todos los coeficientes siginificativos\n",
    "+ Modelo SARIMAX más simple posible que se adecue al comportamiento de la serie temporal\n",
    "+ Variables impulso: Comportamiento del efecto del covid-19\n",
    "+ Coeficientes negativos?\n",
    "+ Ljung-Box test ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residuals analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residual error\n",
    "plt.figure(figsize=[15,15])\n",
    "FT.check_residuals(pd.DataFrame(sarimax_fit.resid.loc[100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Ljung-Box test indica que los residuos son independientes (p-valor > alpha -> No rechazamos H_0:{Residuos independientes})\n",
    "+ Como ya se comentó, existe comportamiento no modelado en la serie temporal\n",
    "+ Residuos aproximadamente normal, aparecen outliers en la cola derecha, comportamiento no modelado (covid-19) o outliers\n",
    "+ De ACF y PACF se observa que el residuo no es ruido blanco, existen correlaciones significativas -> No se ha modelado todo el comportamiento\n",
    "+ Solo a partir de 100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain forecasts for in-sample and out-of-sample\n",
    "# Inicio y horizonte\n",
    "start = 200\n",
    "horizon = 20\n",
    "end = df_ts.shape[0] + horizon\n",
    "\n",
    "# Exog variables\n",
    "exp2Pred = np.concatenate((exp, np.zeros((horizon,2))))\n",
    "\n",
    "pred = sarimax_fit.get_prediction(start=start, end= end, exog= exp[start:start+horizon+1], dynamic=False)\n",
    "yhat = pred.predicted_mean\n",
    "yhat_conf_int = pred.conf_int(alpha=0.05)\n",
    "\n",
    "#Undo Box-cox transform if necessary\n",
    "if BOX_COX:\n",
    "    yhat = sp.special.inv_boxcox(yhat, lmbda)\n",
    "    yhat_conf_int = sp.special.inv_boxcox(yhat_conf_int, lmbda)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.fill_between(yhat_conf_int.index,\n",
    "                yhat_conf_int.iloc[:, 0],\n",
    "                yhat_conf_int.iloc[:, 1], color='k', alpha=.2)\n",
    "plt.plot(df_ts.loc[start:])\n",
    "plt.plot(yhat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction of out_of_sample and confidence intervals\n",
    "# If using dynamic = True, the forecast are used as real data\n",
    "horizon = 20\n",
    "end = df_ts.shape[0] + horizon\n",
    "\n",
    "# COMANDO PREDICCION\n",
    "pred = sarimax_fit.get_forecast(steps=horizon, exog= exp[start:start+horizon], dynamic=False)\n",
    "yhat = pred.predicted_mean\n",
    "yhat_conf_int = pred.conf_int(alpha=0.05)\n",
    "\n",
    "#Undo Box-cox transform if necessary\n",
    "if BOX_COX:\n",
    "    yhat = sp.special.inv_boxcox(yhat, lmbda)\n",
    "    yhat_conf_int = sp.special.inv_boxcox(yhat_conf_int, lmbda)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[15,15])\n",
    "plt.fill_between(yhat_conf_int.index,\n",
    "                yhat_conf_int.iloc[:, 0],\n",
    "                yhat_conf_int.iloc[:, 1], color='k', alpha=.2)\n",
    "plt.plot(df_ts.loc[1000:])\n",
    "plt.plot(yhat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# November 2022 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediccion para steps = 1 (Escala 1 e6)\n",
    "predPreBC = sarimax_fit.get_forecast(steps=1, exog = [0, 0], dynamic=False).predicted_mean\n",
    "if BOX_COX:\n",
    "    pred = sp.special.inv_boxcox(predPreBC, lmbda)\n",
    "\n",
    "print('Prediction:', round(pred.values[0]), 'parados en Noviembre de 2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparacion Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ AIC:\n",
    "+ Coeficientes significativos:\n",
    "+ Residuos: Normalidad, test independencia, ruido blanco, outliers\n",
    "+ Predicciones: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Linear Model (Time series regression model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Buscamos estacional?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aditional data (PIB), shift 1, 2, 12 times Total\n",
    "dfT = df[['TOTAL']].copy()\n",
    "dfT['TOTAL_lag1'] = dfT['TOTAL'].shift()\n",
    "dfT['TOTAL_lag2'] = dfT['TOTAL'].shift(2)\n",
    "dfT['TOTAL_lag12'] = dfT['TOTAL'].shift(3)\n",
    "\n",
    "dfT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missingnvalues from shifting\n",
    "dfT.dropna(inplace=True)\n",
    "dfT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfT = dfT.astype({'TOTAL_lag1': 'int', 'TOTAL_lag2': 'int', 'TOTAL_lag12': 'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output matrices\n",
    "INPUTS = ['TOTAL_lag1','TOTAL_lag2', 'TOTAL_lag12']\n",
    "OUTPUT = 'TOTAL'\n",
    "\n",
    "X = dfT[INPUTS]\n",
    "y = dfT[OUTPUT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training and test sets sequentialy\n",
    "# Create random 80/20 split\n",
    "X_train = X.iloc[0:round(0.8*X.shape[0])]\n",
    "X_test = X.iloc[round(0.8*X.shape[0])+1:X.shape[0]]\n",
    "y_train = y.iloc[0:round(0.8*X.shape[0])]\n",
    "y_test = y.iloc[round(0.8*X.shape[0])+1:X.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset to store model predictions\n",
    "dfTR_eval = X_train.copy()\n",
    "dfTR_eval['Y'] = y_train.copy() \n",
    "dfTS_eval = X_test.copy()\n",
    "dfTS_eval['Y'] = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regression Model\n",
    "# Inputs of the model. \n",
    "INPUTS_NUM = INPUTS.copy()\n",
    "INPUTS_CAT = []\n",
    "INPUTS_MLP = INPUTS_NUM + INPUTS_CAT\n",
    "\n",
    "param = {'MLP__alpha': [0.0001,0.001,0.01], # Initial value of regularization\n",
    "         'MLP__hidden_layer_sizes':[(5,),(13,),(20,),(25,)]} # Number of neurons in each hidden layer, enters as tuples\n",
    "         \n",
    "\"\"\"\n",
    "# Uncomment the two following lines for training a single model\n",
    "param = {'MLP__alpha': [0.000001], # Initial value of regularization\n",
    "         'MLP__hidden_layer_sizes':[(10, 10, 5)]} # Number of neurons in each hidden layer, enters as tuples\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "# Scale data previous to fit and oneHOT\n",
    "# Prepare numeric variables by scaling values\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "# Prepare the categorical variables by encoding the categories\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', drop = 'first'))])\n",
    "# Create a preprocessor to perform the steps defined above\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, INPUTS_NUM),\n",
    "        ('cat', categorical_transformer, INPUTS_CAT)\n",
    "        ])\n",
    "pipe = Pipeline(steps=[('preprocessor',preprocessor), # Preprocess the variables when training the model \n",
    "                       ('MLP', MLPRegressor(solver='lbfgs', # Update function\n",
    "                                             activation='logistic', # Logistic sigmoid activation function\n",
    "                                             #alpha=0.0001, # L2 regularization term\n",
    "                                             #learning_rate='adaptive', # Type of learning rate used in training\n",
    "                                             max_iter=450, # Maximum number of iterations\n",
    "                                             #batch_size=10, # Size of batch when training\n",
    "                                             #tol=1e-4, # Tolerance for the optimization\n",
    "                                             #n_iter_no_change=10, # Maximum number of epochs to not meet tol improvement\n",
    "                                             # random_state=150, # For replication\n",
    "                                             verbose = True))]) #Print progress\n",
    "\n",
    "# We use Grid Search Cross Validation to find the best parameter for the model in the grid defined \n",
    "nFolds = 10\n",
    "MLP_fit = GridSearchCV(estimator=pipe, # Structure of the model to use\n",
    "                       param_grid=param, # Defined grid to search in\n",
    "                       n_jobs=-1, # Number of cores to use (parallelize)\n",
    "                       scoring='neg_mean_squared_error', # RMSE \n",
    "                       cv=nFolds) # Number of Folds \n",
    "MLP_fit.fit(X_train[INPUTS_MLP], y_train) # Search in grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grid error\n",
    "MT.plotModelGridError(MLP_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Analysis\n",
    "\n",
    "mlp = MLP_fit.best_estimator_['MLP']\n",
    "wts = mlp.coefs_\n",
    "bias = mlp.intercepts_\n",
    "actfunc = ['identity',MLP_fit.best_estimator_['MLP'].get_params()['activation'],mlp.out_activation_]\n",
    "X = MLP_fit.best_estimator_['preprocessor'].transform(X_train) # Preprocess the variables\n",
    "coefnames = X_train.columns.values.tolist()\n",
    "X = pd.DataFrame(X, columns=coefnames)\n",
    "y = pd.DataFrame(y_train, columns=['Y'])\n",
    "sens_end_layer = 'last'\n",
    "sens_end_input = False\n",
    "sens_origin_layer = 0\n",
    "sens_origin_input = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensmlp = ns.jacobian_mlp(wts, bias, actfunc, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensmlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensmlp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensmlp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a report of the model based on predictions\n",
    "dfTR_eval['MLP_pred'] = MLP_fit.predict(X_train)\n",
    "dfTS_eval['MLP_pred'] = MLP_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and test errors\n",
    "\n",
    "print('Training MAE:',mean_absolute_error(dfTR_eval['Y'], dfTR_eval['MLP_pred']))\n",
    "print('Test MAE:',mean_absolute_error(dfTS_eval['Y'], dfTS_eval['MLP_pred']))\n",
    "\n",
    "print('Training RMSE:',math.sqrt(mean_squared_error(dfTR_eval['Y'], dfTR_eval['MLP_pred'])))\n",
    "print('Test RMSE:',math.sqrt(mean_squared_error(dfTS_eval['Y'], dfTS_eval['MLP_pred'])))\n",
    "\n",
    "print('Training R2:',r2_score(dfTR_eval['Y'], dfTR_eval['MLP_pred']))\n",
    "print('Test R2:',r2_score(dfTS_eval['Y'], dfTS_eval['MLP_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions of the model\n",
    "sns.scatterplot(x='TOTAL_lag1', y='Y', data=dfTR_eval, color='black', alpha=0.5)\n",
    "sns.scatterplot(x='TOTAL_lag1', y='MLP_pred', data=dfTR_eval, color='red', edgecolor='black').set_title('Predictions for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of residuals\n",
    "RT.plotModelDiagnosis(dfTS_eval, 'MLP_pred', 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction against real value\n",
    "sns.scatterplot(data=dfTS_eval, x='Y', y='Y', color='black', alpha=0.5)\n",
    "sns.scatterplot(data=dfTS_eval, x='MLP_pred', y='Y', color='blue', edgecolor='black')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare forecasts in time\n",
    "plt.figure()\n",
    "plt.plot('Y', data=dfTS_eval, label='Real')\n",
    "plt.plot('MLP_pred', data=dfTS_eval, label='Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation of residuals\n",
    "FT.ts_display(dfTS_eval['Y'] - dfTS_eval['MLP_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Prediction November 2022"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2385fc4aef5e04ad1f7070587c7f6c5e2e88397b4696a09353ed0ed3c263b3dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
